{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhagesh20558/miniconda3/envs/mhcp3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from utils.hfDataset import MHCoPilot_Dataset \n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    ")\n",
    "from peft import (\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    ")\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "# import prompts\n",
    "import torch, wandb\n",
    "# from mh_final.final.model import BertForMultiLabelMulticlassClassification,BertForMultiLabelMulticlassClassificationUtils\n",
    "# import verifier_module_final_dpo_updated as verifier\n",
    "from utils.model import RobertaForMultiLabelMulticlassClassification, RobertaForMultiLabelMulticlassClassificationUtils\n",
    "import prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3331/3331 [00:00<00:00, 6071.04 examples/s]\n",
      "Map: 100%|██████████| 953/953 [00:00<00:00, 6198.84 examples/s]\n",
      "Map: 100%|██████████| 476/476 [00:00<00:00, 6055.58 examples/s]\n",
      "Map: 100%|██████████| 3331/3331 [00:01<00:00, 2757.88 examples/s]\n",
      "Map: 100%|██████████| 953/953 [00:00<00:00, 3885.43 examples/s]\n",
      "Map: 100%|██████████| 476/476 [00:00<00:00, 3754.34 examples/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "Dataset = MHCoPilot_Dataset(\"../data\", task = \"general\", ner = True, make_new_split = False)\n",
    "Dataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spanprediction:\n",
    "    def __init__(self,model,device):\n",
    "        self.id2label = {\n",
    "            0:'O', 1:'B-ES', 2:'I-ES', 3:'B-EFS', 4:'I-EFS', 5:'B-RS', 6:'I-RS'\n",
    "        }\n",
    "        self.label2id = {v:k for k,v in self.id2label.items()}\n",
    "        self.device=device\n",
    "        self.model=AutoModelForTokenClassification.from_pretrained(model,device_map=device,id2label=self.id2label, label2id=self.label2id)\n",
    "        self.tokenizer=AutoTokenizer.from_pretrained(model)\n",
    "        self.tokenizer.add_tokens(['<es>','<efs>','<rs>','<ee>', '<efe>', '<re>'])\n",
    "        self.idx=0\n",
    "    def id_to_label(self,outputs):\n",
    "        return [self.model.config.id2label[t] for t in outputs]\n",
    "\n",
    "    def chunking(self,example,context_size=512):\n",
    "\n",
    "        chunks={'input_ids':[],'attention_mask':[]}\n",
    "        for i in range(0, len(example['input_ids'][0]), context_size):\n",
    "            chunks['input_ids'].append(example['input_ids'][0][i:i+context_size])\n",
    "            chunks['attention_mask'].append(example['attention_mask'][0][i:i+context_size])\n",
    "            # word_ids.append(wordids[i:i+context_size])\n",
    "            if chunks['input_ids'][-1].shape[0]<context_size:\n",
    "                chunks['input_ids'][-1]=torch.cat([chunks['input_ids'][-1],torch.zeros(context_size-chunks['input_ids'][-1].shape[0],dtype=torch.long)])\n",
    "                chunks['attention_mask'][-1]=torch.cat([chunks['attention_mask'][-1],torch.zeros(context_size-chunks['attention_mask'][-1].shape[0],dtype=torch.long)])\n",
    "        chunks['input_ids']=torch.stack(chunks['input_ids']).to(self.device)\n",
    "        chunks['attention_mask']=torch.stack(chunks['attention_mask']).to(self.device)\n",
    "        return chunks\n",
    "\n",
    "    def predict(self,text):\n",
    "        self.idx=0\n",
    "        inputs = self.tokenizer(text, padding=\"max_length\",return_tensors=\"pt\",truncation=False)\n",
    "        # original_inputs=self.tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        token_ids=inputs.word_ids()\n",
    "        chunks=self.chunking(inputs)\n",
    "        original_inputs=inputs['input_ids'][0]\n",
    "        outputs = self.model(**chunks,).logits.cpu()\n",
    "        if outputs.shape[0]>1:\n",
    "            outputs=outputs.reshape(1,outputs.shape[1]*outputs.shape[0],outputs.shape[2])\n",
    "            outputs=outputs[:,outputs.shape[1]-original_inputs.shape[0]:,:]\n",
    "        # outputs=outputs.reshape(1,outputs.shape[1]*outputs.shape[0],outputs.shape[2])\n",
    "        # print(outputs.shape)\n",
    "        attention_mask=inputs['attention_mask'][0]\n",
    "        mask = attention_mask.view(-1) == 1  # Get non-padding indices\n",
    "        outputs = torch.argmax(outputs*attention_mask.unsqueeze(-1),dim=2)\n",
    "        filtered_preds = torch.masked_select(outputs.view(-1), mask)\n",
    "        outputs = [self.model.config.id2label[t.item()] for t in filtered_preds]\n",
    "        result=self.process_otuput(original_inputs,outputs,token_ids)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def predict_batch(self,texts):\n",
    "        # inputs = self.tokenizer(texts, padding=\"max_length\",return_tensors=\"pt\")\n",
    "        # # original_inputs=self.tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "        # inputs.to(self.device)\n",
    "        # outputs = self.model(**inputs).logits\n",
    "        # l=[]\n",
    "        # for i in range(outputs.shape[0]):\n",
    "        #     temp=outputs[i].unsqueeze(0)\n",
    "        #     attention_mask=inputs['attention_mask'][i].unsqueeze(0)\n",
    "        #     mask = attention_mask.view(-1) == 1  # Get non-padding indices\n",
    "        #     labels = torch.argmax(temp*attention_mask.unsqueeze(-1),dim=2)\n",
    "        #     filtered_preds = torch.masked_select(labels.view(-1), mask)\n",
    "        #     labels = [self.model.config.id2label[t.item()] for t in filtered_preds]\n",
    "        #     token_ids=inputs.word_ids(batch_index=i)\n",
    "        #     original_inputs=inputs['input_ids'][i]\n",
    "        #     l.append(self.process_otuput(original_inputs,labels,token_ids))\n",
    "        # return l\n",
    "        l=[]\n",
    "        for i in texts:\n",
    "            l.append(self.predict(i))\n",
    "        return l\n",
    "    \n",
    "    def process_otuput(self,inputs,preds,input_ids):\n",
    "        tags={'B-ES':'<es>', 'I-ES':'<ee>', 'B-EFS':'<efs>', 'I-EFS':'<efe>', 'B-RS':'<rs>', 'I-RS':'<re>'}\n",
    "        d2={}\n",
    "        z=0\n",
    "        for i in range(len(input_ids)):\n",
    "            if input_ids[i]!=None:\n",
    "                z=max(z,input_ids[i])\n",
    "                if input_ids[i] not in d2:\n",
    "                    d2[input_ids[i]]={\"inputs\":[inputs[i]],\"preds\":[preds[i]]}\n",
    "                else:\n",
    "                    d2[input_ids[i]][\"inputs\"].append(inputs[i])\n",
    "                    d2[input_ids[i]][\"preds\"].append(preds[i])\n",
    "        s=[]\n",
    "        labels=[]\n",
    "        for i in d2:\n",
    "            s.append(self.tokenizer.decode(d2[i]['inputs']) )\n",
    "            labels.append(d2[i]['preds'][0])\n",
    "\n",
    "        s2=[]\n",
    "        for i in range(len(s)):\n",
    "            if 'B' in labels[i]:\n",
    "                s2.append(tags[labels[i]])\n",
    "                s2.append(s[i])\n",
    "            elif i<len(s)-1 and labels[i] in tags and labels[i+1] not in tags:\n",
    "                s2.append(s[i])\n",
    "                s2.append(tags[labels[i]])\n",
    "            else :\n",
    "                s2.append(s[i])\n",
    "        return \"\".join(s2)\n",
    "        \n",
    "class level_classifier:\n",
    "    def __init__(self,base_name,model,device):\n",
    "        self.device=device\n",
    "        checkpoint = torch.load(model)\n",
    "        self.model = RobertaForMultiLabelMulticlassClassification.from_pretrained(\n",
    "            base_name, \n",
    "            num_labels=3,  # For 'event', 'effect', 'requirement'\n",
    "            num_classes_per_label=3,  # Since each label can take values 0, 1, or 2\n",
    "            device_map=device,\n",
    "        )\n",
    "        self.tokenizer=self.tokenizer = AutoTokenizer.from_pretrained(base_name)\n",
    "        self.tokenizer.add_tokens(['<es>','<efs>','<rs>','<ee>', '<efe>', '<re>'])\n",
    "        self.tokenizer.truncation_side=\"left\"\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        self.model.load_state_dict(checkpoint)\n",
    "        \n",
    "    def predict(self,text):\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        inputs.to(self.device)\n",
    "        outputs = self.model(**inputs)\n",
    "        outputs = torch.argmax(outputs, dim=1)\n",
    "        return outputs[0]\n",
    "    \n",
    "    def predict_batch(self,text):\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        inputs.to(self.device)\n",
    "        outputs = self.model(**inputs)\n",
    "        outputs = torch.argmax(outputs, dim=1)\n",
    "        return outputs\n",
    "    \n",
    "class generator:\n",
    "    def load_model(self,base_model,model_name,model_type):\n",
    "        tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "        tokenizer.truncation_side=\"left\"\n",
    "        tokenizer.padding_side=\"left\"\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        load_in_8bit=True,\n",
    "        torch_dtype = torch.bfloat16,\n",
    "        attn_implementation=self.attn_implementation,\n",
    "        device_map=self.device\n",
    "        )\n",
    "        if model_type==\"dpo\":\n",
    "            peft_model = PeftModel.from_pretrained(model, model_name+\"/train1\")\n",
    "        elif model_type==\"sft\":\n",
    "            peft_model = PeftModel.from_pretrained(model, model_name)\n",
    "        peft_model.config.use_cache = True\n",
    "        return peft_model,tokenizer\n",
    "    \n",
    "    def __init__(self,base_model,model,device,model_type):\n",
    "        self.device=device\n",
    "        self.attn_implementation=\"flash_attention_2\"\n",
    "        self.model,self.tokenizer=self.load_model(base_model,model,model_type)\n",
    "        self.generation_kwargs={\"num_return_sequences\":1,\"max_new_tokens\":100}\n",
    "        self.context_length=1024\n",
    "        self.prompt_template=prompts.gemma_get_prompt\n",
    "        self.system_prompt='''A support seeker on a peer-to-peer (P2P) Online Mental Health Platform (OMHP) is an individual who utilizes digital services to seek assistance/help for managing and improving their mental health, typically through interactions with peer groups or self-help resources.\n",
    "        The parameters are defined as follows:\n",
    "            Event: This parameter encapsulates the specific situation, activity, or event that is the focal point of the support seeker’s concern. The explicit detailing of such events provides a contextual background essential for empathetic understanding.\n",
    "            Effect: This aspect targets the impact or consequences of the identified event on the support seeker. By elucidating the effect, the post conveys the emotional or practical repercussions of the event, thereby inviting more targeted and empathetic responses. \n",
    "            Requirement: This parameter is critical in directing the nature of the assistance sought. It ranges from emotional and informational support to instrumental aid, thereby guiding the potential response trajectory.\n",
    "\n",
    "        In the posts on OMHP these parameters can have intensity ranging from 0 to 2, where 0 means absent, 1 means present but needs clarification and 2 being well described based on the presence of these parameters in the post\n",
    "\n",
    "            Consider the following post by a support seeker on a OMHP, in which the spans of text representing Event, Effect and Requirement have been marked. Also, the intensity levels for each of the parameters in the post have been provided along with the post.\n",
    "            The post is context of the victim.\n",
    "            The post <es> and <ee> tags encapsulate the spans for the Event parameter, <efs> and <efe> tags encapsulate the spans for the Effect parameter, and <rs> and <re> tags encapsulate the spans for the Requirement parameter.\n",
    "        '''\n",
    "    def prepare_eval(self,annotated_post_body,levels):\n",
    "        post=annotated_post_body\n",
    "        note=\"Generate 3 questions following the schema according to the scale of event, effect and requirement provided below the post, for helping the support giver to understand more about the victim.Strictly follow the question format of schema.Give only the json output as specified in the schema and no explanation needed.\"\n",
    "        prompt=\"Post: \"+post+\"\\n\\n\"+\"event scale: \"+str(levels[0].item())+\" effect scale: \"+str(levels[1].item())+\" requirement scale: \"+str(levels[2].item())+\"\\n\\n\"+\"schema:\\n\"+'''{\"event_question\": \"\",\"effect_question\": \"\",\"requirement_question\": \"\"}'''+\"\\n\\n\"+note\n",
    "        # print(prompt)\n",
    "        model_input=self.prompt_template(self.system_prompt,prompt)\n",
    "        return model_input\n",
    "\n",
    "    def generate(self,annotated_post_body,levels):\n",
    "        print(levels)\n",
    "\n",
    "        text=[self.prepare_eval(annotated_post_body[i],levels[i].detach().cpu()) for i in range(len(annotated_post_body))]\n",
    "        inputs = self.tokenizer(text, return_tensors='pt',padding=True, \n",
    "                            max_length=self.context_length,truncation=True).to(\"cuda:0\")\n",
    "        preds=[]\n",
    "        inputs.to(self.device)\n",
    "        outputs = self.model.generate(**inputs,**self.generation_kwargs)\n",
    "        text = self.tokenizer.batch_decode(outputs[:,inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "        for i in text:\n",
    "            preds.append(i)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Burnt out in my current career and unsure of where to go next', 'body': 'I (F, 25, ADHD combination type) have been with my current company for about a year and a half. It started out great!\\n\\nThings I enjoyed initially:\\n\\n• Flexible boss\\n\\n• Engaging projects\\n\\n• Good individual &amp; teamwork balance \\n\\n• The fact that I was working in a field that somewhat aligned with my college education\\n\\nAbout 5 months in, things changed and it has been quite the trainwreck:\\n\\n•Lost motivation/interest for even the simplest tasks &amp; projects\\n\\n•Made some pretty significant mistakes due to poor planning/time management and lack of attention to detail\\n\\n•Work-life balance is shot due to 50-80 hour work weeks including weekends during the fall, winter and early spring- my personal life is really important to me and it has taken a huge hit as a result\\n\\n• Coworkers treat me like I’m incompetent &amp; constantly talk about me within earshot (no help from our boss) \\n\\nI’ve tried nearly every trick/tip to manage my ADHD symptoms at work but I’ve realized this job &amp; work culture is just not a good fit for me. As a result, I have been looking for a career change the last 8 months with no luck. My lack of luck probably has to do with the fact I’m terrified of ending up in a similar position and cannot decide what path to pursue.\\n\\nI’m considering a career change to something in design or marketing which aligns well with my personality, interests, &amp; work style, but the jump from science, to either of the previously mentioned options, is also making me scared. \\n\\nIn any case, I’m tired, frustrated and feeling pretty down about my current situation (I’m in jeopardy of losing my job at this point) and I really needed to get it off my chest. \\n\\nTl; dr- I need a new career but induced anxiety from ADHD shortcomings is holding me back and I’m not sure where to go from here.', 'annotated_post_body': '<es>I (F, 25, ADHD combination type) have been with my current company for about a year and a half.<ee> <es>It started out great!<ee>  <es>Things I enjoyed initially:<ee>  <es>• Flexible boss<ee>  <es>• Engaging projects<ee>  <es>• Good individual &amp; teamwork balance <ee>  <es>• The fact that I was working in a field that somewhat aligned with my college education<ee>  <es>About 5 months in, things changed and it has been quite the trainwreck:<ee>  <efs>•Lost motivation/interest for even the simplest tasks &amp; projects<efe>  <es>•Made some pretty significant mistakes due to poor planning/time management and lack of attention to detail<ee>  <es>•Work-life balance is shot due to 50-80 hour work weeks including weekends during the fall, winter and early spring- my personal life is really important to me and it has taken a huge hit as a result<ee>  <es>• Coworkers treat me like I’m incompetent &amp; constantly talk about me within earshot (no help from our boss) <ee>  <es>I’ve tried nearly every trick/tip to manage my ADHD symptoms at work but I’ve realized this job &amp; work culture is just not a good fit for me.<ee> <es>As a result, I have been looking for a career change the last 8 months with no luck.<ee> <efs>My lack of luck probably has to do with the fact I’m terrified of ending up in a similar position and cannot decide what path to pursue.<efe>  <rs>I’m considering a career change to something in design or marketing which aligns well with my personality, interests, &amp; work style, but the jump from science, to either of the previously mentioned options, is also making me scared. <re>  <efs>In any case, I’m tired, frustrated and feeling pretty down about my current situation (I’m in jeopardy of losing my job at this point). <rs>I really needed to get it off my chest. <re>  <es>Tl; dr- I need a new career but induced anxiety from ADHD shortcomings is holding me back and I’m not sure where to go from here.<ee>', 'ES': '2', 'EFS': 2, 'RS': 2, 'EMaskingQ': '', 'EMask': '', 'EFSMaskingQ': '', 'EFSMask': '', 'RMaskingQ': '', 'RMask': '', 'labels': [2.0, 2.0, 2.0], 'ner_tokens': ['I', 'F', '25', 'ADHD', 'combination', 'type', 'have', 'been', 'with', 'my', 'current', 'company', 'for', 'about', 'a', 'year', 'and', 'a', 'half', 'It', 'started', 'out', 'great', 'Things', 'I', 'enjoyed', 'initially', 'Flexible', 'boss', 'Engaging', 'projects', 'Good', 'individual', 'amp', 'teamwork', 'balance', 'The', 'fact', 'that', 'I', 'was', 'working', 'in', 'a', 'field', 'that', 'somewhat', 'aligned', 'with', 'my', 'college', 'education', 'About', '5', 'months', 'in', 'things', 'changed', 'and', 'it', 'has', 'been', 'quite', 'the', 'trainwreck', 'Lost', 'motivation', 'interest', 'for', 'even', 'the', 'simplest', 'tasks', 'amp', 'projects', 'Made', 'some', 'pretty', 'significant', 'mistakes', 'due', 'to', 'poor', 'planning', 'time', 'management', 'and', 'lack', 'of', 'attention', 'to', 'detail', 'Work', 'life', 'balance', 'is', 'shot', 'due', 'to', '50', '80', 'hour', 'work', 'weeks', 'including', 'weekends', 'during', 'the', 'fall', 'winter', 'and', 'early', 'spring', 'my', 'personal', 'life', 'is', 'really', 'important', 'to', 'me', 'and', 'it', 'has', 'taken', 'a', 'huge', 'hit', 'as', 'a', 'result', 'Coworkers', 'treat', 'me', 'like', 'I', 'm', 'incompetent', 'amp', 'constantly', 'talk', 'about', 'me', 'within', 'earshot', 'no', 'help', 'from', 'our', 'boss', 'I', 've', 'tried', 'nearly', 'every', 'trick', 'tip', 'to', 'manage', 'my', 'ADHD', 'symptoms', 'at', 'work', 'but', 'I', 've', 'realized', 'this', 'job', 'amp', 'work', 'culture', 'is', 'just', 'not', 'a', 'good', 'fit', 'for', 'me', 'As', 'a', 'result', 'I', 'have', 'been', 'looking', 'for', 'a', 'career', 'change', 'the', 'last', '8', 'months', 'with', 'no', 'luck', 'My', 'lack', 'of', 'luck', 'probably', 'has', 'to', 'do', 'with', 'the', 'fact', 'I', 'm', 'terrified', 'of', 'ending', 'up', 'in', 'a', 'similar', 'position', 'and', 'cannot', 'decide', 'what', 'path', 'to', 'pursue', 'I', 'm', 'considering', 'a', 'career', 'change', 'to', 'something', 'in', 'design', 'or', 'marketing', 'which', 'aligns', 'well', 'with', 'my', 'personality', 'interests', 'amp', 'work', 'style', 'but', 'the', 'jump', 'from', 'science', 'to', 'either', 'of', 'the', 'previously', 'mentioned', 'options', 'is', 'also', 'making', 'me', 'scared', 'In', 'any', 'case', 'I', 'm', 'tired', 'frustrated', 'and', 'feeling', 'pretty', 'down', 'about', 'my', 'current', 'situation', 'I', 'm', 'in', 'jeopardy', 'of', 'losing', 'my', 'job', 'at', 'this', 'point', 'I', 'really', 'needed', 'to', 'get', 'it', 'off', 'my', 'chest', 'Tl', 'dr', 'I', 'need', 'a', 'new', 'career', 'but', 'induced', 'anxiety', 'from', 'ADHD', 'shortcomings', 'is', 'holding', 'me', 'back', 'and', 'I', 'm', 'not', 'sure', 'where', 'to', 'go', 'from', 'here'], 'ner_labels': [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]}\n"
     ]
    }
   ],
   "source": [
    "test_data=Dataset.test_df\n",
    "print(test_data[1])\n",
    "test_data=test_data.remove_columns(['title', 'annotated_post_body', 'EMaskingQ', 'EMask', 'EFSMaskingQ', 'EFSMask', 'RMaskingQ', 'RMask', 'labels', 'ner_tokens', 'ner_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "span_model=\"../spanpred/results_roberta-testing\"\n",
    "span_predictor=spanprediction(span_model,\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMultiLabelMulticlassClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "level_model=level_classifier(\"roberta-base\",\"checkpoints/clf_RoBERTa-ordinal.pt\",\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "gen_dpo_model=generator(\"google/gemma-2b-it\",\"../Pipeline/gemma2-dpo-2final\",\"cuda:0\",\"dpo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 1],\n",
      "        [2, 2, 1],\n",
      "        [2, 1, 0],\n",
      "        [2, 0, 1],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/17 [00:09<02:34,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 0, 0],\n",
      "        [1, 1, 2],\n",
      "        [1, 1, 2],\n",
      "        [1, 2, 0],\n",
      "        [1, 1, 1],\n",
      "        [2, 1, 1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2/17 [00:18<02:15,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 1],\n",
      "        [1, 0, 2],\n",
      "        [1, 1, 0],\n",
      "        [1, 0, 2],\n",
      "        [2, 0, 0],\n",
      "        [0, 1, 2]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3/17 [00:27<02:05,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 0, 0],\n",
      "        [2, 1, 1],\n",
      "        [1, 1, 2],\n",
      "        [2, 1, 1],\n",
      "        [1, 1, 0],\n",
      "        [2, 2, 1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4/17 [00:34<01:50,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 2],\n",
      "        [2, 1, 1],\n",
      "        [2, 1, 1],\n",
      "        [1, 0, 0],\n",
      "        [2, 1, 0],\n",
      "        [2, 0, 1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5/17 [00:43<01:41,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2, 1],\n",
      "        [1, 1, 1],\n",
      "        [2, 2, 0],\n",
      "        [1, 2, 1],\n",
      "        [2, 1, 1],\n",
      "        [1, 0, 2]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 6/17 [00:52<01:34,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 1],\n",
      "        [2, 1, 0],\n",
      "        [2, 2, 0],\n",
      "        [1, 1, 1],\n",
      "        [1, 0, 2],\n",
      "        [2, 1, 0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [01:00<01:26,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 2],\n",
      "        [1, 0, 2],\n",
      "        [2, 1, 0],\n",
      "        [2, 0, 1],\n",
      "        [1, 2, 2],\n",
      "        [1, 2, 0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 8/17 [01:09<01:17,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 1, 1],\n",
      "        [2, 0, 0],\n",
      "        [1, 0, 2],\n",
      "        [2, 2, 1],\n",
      "        [1, 1, 0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9/17 [01:18<01:09,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 0, 2],\n",
      "        [2, 2, 1],\n",
      "        [1, 1, 1],\n",
      "        [0, 1, 2],\n",
      "        [0, 1, 2]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 10/17 [01:27<01:00,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 1],\n",
      "        [2, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 0, 2],\n",
      "        [2, 0, 1],\n",
      "        [2, 1, 1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 11/17 [01:35<00:52,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 2],\n",
      "        [2, 1, 1],\n",
      "        [1, 0, 2],\n",
      "        [2, 1, 1],\n",
      "        [0, 2, 1],\n",
      "        [2, 1, 1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 12/17 [01:43<00:42,  8.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 2],\n",
      "        [2, 1, 0],\n",
      "        [2, 1, 2],\n",
      "        [2, 1, 1],\n",
      "        [1, 1, 0],\n",
      "        [2, 1, 1]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 13/17 [01:52<00:34,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 1],\n",
      "        [2, 0, 0],\n",
      "        [1, 0, 0],\n",
      "        [1, 1, 2],\n",
      "        [1, 1, 0],\n",
      "        [1, 1, 2]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 14/17 [02:01<00:25,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 2],\n",
      "        [1, 0, 2],\n",
      "        [2, 0, 1],\n",
      "        [2, 1, 2],\n",
      "        [1, 1, 2],\n",
      "        [1, 0, 2]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 15/17 [02:08<00:16,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 1],\n",
      "        [1, 1, 2],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 2],\n",
      "        [1, 0, 2],\n",
      "        [0, 1, 2]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 16/17 [02:15<00:08,  8.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 1],\n",
      "        [1, 1, 2],\n",
      "        [1, 1, 1],\n",
      "        [1, 2, 0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [02:24<00:00,  8.50s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def prepare(row):\n",
    "    return row\n",
    "from torch.utils.data import DataLoader\n",
    "test_data=test_data.map(prepare,batched=False).select(range(100))\n",
    "dataloader = DataLoader(test_data, batch_size=6,shuffle=False)\n",
    "d={'post':[],\"spans\":[],\"levels\":[]}\n",
    "l=[]\n",
    "d['dpo_questions']=[]\n",
    "t=0\n",
    "for batch in tqdm(dataloader,total=len(dataloader)):\n",
    "    span_output=l[t][0]\n",
    "    level_output=l[t][1]\n",
    "    gen_output=gen_dpo_model.generate(span_output,level_output)\n",
    "    # d['post'].extend(batch['body']\n",
    "    t+=1\n",
    "    d['dpo_questions'].extend([json.loads(output.strip()) for output in gen_output])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhcp3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
